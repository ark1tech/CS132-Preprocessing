{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependencies and set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import spacy    \n",
    "import spacy_transformers\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn import decomposition\n",
    "import numpy as np \n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px # pip install plotly\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "%matplotlib inline\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "import textwrap\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "df = pd.read_csv(\"../dataset/_compiled/Labelled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, TF-IDF Vectorization, LDA Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(cell):\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", cell) \n",
    "\n",
    "def my_tokenizer(text):\n",
    "    # 1-gram tokens of more than a character\n",
    "    word_tokens = [x for x in word_tokenize(text) if len(x) > 2]\n",
    "    # remove stop words \n",
    "    filtered_tokens = [word for word in word_tokens if word not in set([remove_punctuation(x) for x in [*stopwords.words('english'), *nlp.Defaults.stop_words, *[str(x) for x in open(\"stop_words.txt\", \"r\").read().split(\" \")]]])]\n",
    "    # lemmatize the tokens \n",
    "    # lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Topic ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leave company health pay sick salary absent money medical contract time mental vacation hospital resign</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job company interview human offer resource manager time resignation applied resign hiring salary application process</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people team company good boss time job management coworkers bad companies post business experience toxic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labor pay department company employees employment employer clearance meeting coe overtime human file resource need</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job hours time salary working company home shift office overtime increase pay schedule experience good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               Keywords  \\\n",
       "0               leave company health pay sick salary absent money medical contract time mental vacation hospital resign   \n",
       "1  job company interview human offer resource manager time resignation applied resign hiring salary application process   \n",
       "2              people team company good boss time job management coworkers bad companies post business experience toxic   \n",
       "3    labor pay department company employees employment employer clearance meeting coe overtime human file resource need   \n",
       "4                job hours time salary working company home shift office overtime increase pay schedule experience good   \n",
       "\n",
       "   Topic ID  \n",
       "0         1  \n",
       "1         2  \n",
       "2         3  \n",
       "3         4  \n",
       "4         5  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer,\n",
    "                                min_df = 3, max_df=0.7, max_features=15000, \n",
    "                                use_idf=True, norm=None, token_pattern=None)\n",
    "tf_vectors = tf_vectorizer.fit_transform(df[\"Translated\"])  \n",
    "\n",
    "# Topic Modelling using LDA\n",
    "\n",
    "n_topics = 5\n",
    "lda = decomposition.LatentDirichletAllocation(n_components=n_topics, max_iter=25, \n",
    "                                              learning_method='online', learning_offset=45, n_jobs=1, random_state=420)\n",
    "W = lda.fit_transform(tf_vectors)\n",
    "H = lda.components_\n",
    "\n",
    "# Show top 15 relevant words for each topic\n",
    "\n",
    "num_words = 15\n",
    "vocab = np.array(tf_vectorizer.get_feature_names_out())\n",
    "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "topic_words = ([top_words(t) for t in H])\n",
    "topics = [' '.join(t) for t in topic_words]\n",
    "df_topics = pd.DataFrame(topics, columns=['Keywords'])\n",
    "df_topics['Topic ID'] = range(1, len(topics) + 1)\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Submission 1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>Topic 4: 0.65\\nTopic 3: 0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic 2: 0.71\\nTopic 3: 0.2\\nTopic 4: 0.06\\nTopic 5: 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 3</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic 1: 0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 4</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic 1: 0.74\\nTopic 5: 0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 5</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5</td>\n",
       "      <td>Topic 5: 0.52\\nTopic 1: 0.32\\nTopic 4: 0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic 1  Topic 2  Topic 3  Topic 4  Topic 5  dominant_topic  \\\n",
       "Submission 1     0.00     0.00     0.35     0.65     0.00               4   \n",
       "Submission 2     0.00     0.71     0.20     0.06     0.03               2   \n",
       "Submission 3     0.99     0.00     0.00     0.00     0.00               1   \n",
       "Submission 4     0.74     0.00     0.00     0.00     0.26               1   \n",
       "Submission 5     0.32     0.00     0.00     0.15     0.52               5   \n",
       "\n",
       "                                                              breakdown  \n",
       "Submission 1                               Topic 4: 0.65\\nTopic 3: 0.35  \n",
       "Submission 2  Topic 2: 0.71\\nTopic 3: 0.2\\nTopic 4: 0.06\\nTopic 5: 0.03  \n",
       "Submission 3                                              Topic 1: 0.99  \n",
       "Submission 4                               Topic 1: 0.74\\nTopic 5: 0.26  \n",
       "Submission 5                Topic 5: 0.52\\nTopic 1: 0.32\\nTopic 4: 0.15  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign topic to each submision\n",
    "topicid = [\"Topic \" + str(i+1) for i in range(lda.n_components)]\n",
    "postid = [\"Submission \" + str(i+1) for i in range(len(df[\"Translated\"]))]\n",
    "\n",
    "df_topics_lda = pd.DataFrame(np.round(W,2), columns=topicid, index=postid)\n",
    "significanttopic = np.argmax(df_topics_lda.values, axis=1)+1\n",
    "\n",
    "df_topics_lda['dominant_topic'] = significanttopic\n",
    "df_topics_lda['breakdown'] = df_topics_lda.apply(lambda row: '\\n'.join([f'{col}: {row[col]}' \n",
    "                                                        for col in sorted(df_topics_lda.columns, key=lambda x: row[x], reverse=True) \n",
    "                                                        if row[col] > 0 and col != 'dominant_topic']), axis=1)\n",
    "df_topics_lda.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE Clustering and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "# Apply t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2, random_state=690, perplexity=150)\n",
    "tsne_result = tsne.fit_transform(df_topics_lda.iloc[:,:n_topics])\n",
    "\n",
    "# Create a new dataframe with t-SNE coordinates and cluster labels\n",
    "def split_text(text, max_length):\n",
    "  lines = textwrap.wrap(text, width=max_length, break_long_words=False)\n",
    "  return \"<br>\".join(lines)\n",
    "\n",
    "df_topics_cluster = pd.DataFrame({'X': tsne_result[:, 0],\n",
    "                                  'Y': tsne_result[:, 1],\n",
    "                                  'Submission': df[\"Translated\"],\n",
    "                                  'Engagement': df[\"Engagements\"],\n",
    "                                  'Timestamp': df['Epoch'],\n",
    "                                  'Cluster': df_topics_lda.reset_index()['dominant_topic'].astype(str), # topics via LDA\n",
    "                                  'Breakdown': df_topics_lda.reset_index()['breakdown']})\n",
    "                                  # 'Cluster': cluster_labels},                                         # clusters via K-means\n",
    "\n",
    "df_topics_cluster['Submission'] = df_topics_cluster['Submission'].apply(lambda x: split_text(x, 40))\n",
    "df_topics_cluster['Breakdown'] = df_topics_cluster['Breakdown'].str.replace('\\n','<br>')\n",
    "\n",
    "df_top_10 = df_topics_cluster.sort_values('Engagement', ascending=False).groupby('Cluster').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutshell Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot submissions as colored points\n",
    "df_topics_cluster.sort_values('Cluster', key=lambda x: pd.to_numeric(x, errors='coerce'), inplace=True)\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#785ef0', '#dede00']\n",
    "\n",
    "Design_Book=[\n",
    "              '#ffb000', \n",
    "              '#785ef0', \n",
    "              '#dc267f', \n",
    "              '#fe6100', \n",
    "              '#57c4ff', \n",
    "              '#00cc96', \n",
    "              '#bcbd21', \n",
    "              '#a65628', \n",
    "              '#dede00',\n",
    "              '#984ea3',\n",
    "            ]\n",
    "\n",
    "fig = px.scatter(df_topics_cluster, x='X', y='Y', color='Cluster', \n",
    "                 title='Topic Clustering using LDA and t-SNE',\n",
    "                 hover_name='Submission',\n",
    "                 size='Engagement',\n",
    "                 color_discrete_sequence=Design_Book,\n",
    "                 hover_data={'X':False, 'Y':False, 'Cluster':False, 'Submission':False, 'Breakdown':True})\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=0,\n",
    "    y=-0.2*(1/10)-0.15,\n",
    "    text=\"Top 10 Most Frequent Keywords per Topic\",\n",
    "    showarrow=False,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    align='left',\n",
    "    font=dict(color='white', family='Arial', size=16, weight='normal')\n",
    "  )\n",
    "\n",
    "for i, keyword in enumerate(df_topics['Keywords']):\n",
    "  fig.add_annotation(\n",
    "    x=0,\n",
    "    y=-0.2*(i/5)-0.25,\n",
    "    text=\"Topic %d: %s\"%(i+1, keyword.replace(' ', ', ')),\n",
    "    showarrow=False,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    align='left',\n",
    "    font=dict(color=fig.data[i].marker['color'], family='Arial', size=16, weight='normal')\n",
    "  )\n",
    "\n",
    "SIZE_MULTIPLIER = 1\n",
    "\n",
    "fig.update_traces(mode='markers', \n",
    "                  opacity=1,\n",
    "                  marker=dict(\n",
    "                    sizemode='area',\n",
    "                    sizeref=2.*max(df['Engagements'])/((125*(SIZE_MULTIPLIER))**2), \n",
    "                    line_color='#1a181c',\n",
    "                    line_width=2),\n",
    "                  )\n",
    "\n",
    "fig.update_layout(height=1080*SIZE_MULTIPLIER,\n",
    "                  width=1480*SIZE_MULTIPLIER,\n",
    "                  xaxis=dict(\n",
    "                    gridwidth=2,\n",
    "                    title='',\n",
    "                    color='gray',\n",
    "                  ),\n",
    "                  yaxis=dict(\n",
    "                    gridwidth=2,\n",
    "                    title='',\n",
    "                    color='gray',\n",
    "                  ),\n",
    "                  margin=dict(b=360*SIZE_MULTIPLIER),\n",
    "                  title=dict(font=dict(color='white', family='Roboto', size=24, weight='bold')),\n",
    "                  showlegend=False, \n",
    "                  paper_bgcolor='#1a181c',\n",
    "                  plot_bgcolor='#1a181c',\n",
    "                )\n",
    "\n",
    "fig.update_xaxes(showline=True, \n",
    "                 linewidth=2, \n",
    "                 linecolor='#232024', \n",
    "                 gridcolor='#232024', \n",
    "                 zerolinecolor='#232024',\n",
    "                 title_font_color=\"white\")\n",
    "\n",
    "fig.update_yaxes(showline=True,\n",
    "                 linewidth=2, \n",
    "                 linecolor='#232024', \n",
    "                 gridcolor='#232024', \n",
    "                 zerolinecolor='#232024',\n",
    "                 title_font_color=\"#FFFFFF\")\n",
    "                \n",
    "\n",
    "# !pip install nbformat\n",
    "# restart kernel\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics_cluster['Date'] = pd.to_datetime(df_topics_cluster['Timestamp'], unit='s').dt.to_period('M')\n",
    "# df_topics_cluster = df_topics_cluster.sort_values(by='Timestamp')\n",
    "\n",
    "# total_count = df_topics_cluster.groupby('Date').nunique()\n",
    "# total_count = total_count['Submission'].cumsum()\n",
    "# cumulative_count = df_topics_cluster.groupby(['Date','Cluster']).nunique()\n",
    "# cumulative_count = cumulative_count.pivot_table('Submission', 'Date', 'Cluster').fillna(0).cumsum()\n",
    "\n",
    "# rel_freq = cumulative_count.div(total_count, axis=0)\n",
    "# rel_freq = rel_freq.stack(0).reset_index()\n",
    "# rel_freq.columns = ['Date', 'Cluster', 'Relative Frequency']\n",
    "# rel_freq['Date'] = [x.strftime('%b %Y') for x in rel_freq['Date']]\n",
    "\n",
    "# monthly_count = df_topics_cluster.groupby(['Date','Cluster']).size()\n",
    "# monthly_count = monthly_count.reset_index()\n",
    "# monthly_count.columns = ['Date', 'Cluster', 'Frequency']\n",
    "# monthly_count['Date'] = [x.strftime('%b %Y') for x in monthly_count['Date']]\n",
    "\n",
    "# cumulative_count = cumulative_count.stack(0).reset_index()\n",
    "# cumulative_count.columns = ['Date', 'Cluster', 'Frequency']\n",
    "# cumulative_count['Date'] = [x.strftime('%b %Y') for x in cumulative_count['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.area(monthly_count, x='Date', y='Frequency', color='Cluster',\n",
    "#               title='Relative Frequency vs Time',\n",
    "#               color_discrete_sequence=Design_Book,\n",
    "#               labels={'Relative_Frequency': 'Relative Frequency', 'Date': 'Date'}\n",
    "#             )\n",
    "\n",
    "# fig.update_xaxes(nticks=7)\n",
    "\n",
    "# fig.update_layout(height=1080,\n",
    "#                   width=2160,\n",
    "#                   xaxis=dict(\n",
    "#                     gridwidth=2,\n",
    "#                     title='',\n",
    "#                     color='gray',\n",
    "#                   ),\n",
    "#                   yaxis=dict(\n",
    "#                     gridwidth=2,\n",
    "#                     title='',\n",
    "#                     color='gray',\n",
    "#                   ),\n",
    "#                   title=dict(font=dict(color='white', family='Roboto', size=24, weight='bold')),\n",
    "#                   legend=dict(title=\"Topic\", font=dict(color='white', family='Roboto', size=16, weight='normal')),\n",
    "#                   paper_bgcolor='#1a181c',\n",
    "#                   plot_bgcolor='#1a181c',\n",
    "#                 )\n",
    "\n",
    "# fig.update_xaxes(showline=True, \n",
    "#                  linewidth=2, \n",
    "#                  linecolor='#232024', \n",
    "#                  gridcolor='#232024', \n",
    "#                  zerolinecolor='#232024',\n",
    "#                  title_font_color=\"white\")\n",
    "\n",
    "# fig.update_yaxes(showline=True,\n",
    "#                  linewidth=2, \n",
    "#                  linecolor='#232024', \n",
    "#                  gridcolor='#232024', \n",
    "#                  zerolinecolor='#232024',\n",
    "#                  title_font_color=\"#FFFFFF\")\n",
    "\n",
    "# # Show the plot\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
