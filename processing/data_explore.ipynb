{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependencies and set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import spacy    \n",
    "import spacy_transformers\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn import decomposition\n",
    "import numpy as np \n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px # pip install plotly\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "%matplotlib inline\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "import textwrap\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "df = pd.read_csv(\"../dataset/_compiled/Labelled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, TF-IDF Vectorization, LDA Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(cell):\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", cell) \n",
    "\n",
    "def my_tokenizer(text):\n",
    "    # 1-gram tokens of more than a character\n",
    "    word_tokens = [x for x in word_tokenize(text) if len(x) > 2]\n",
    "    # remove stop words \n",
    "    filtered_tokens = [word for word in word_tokens if word not in set([remove_punctuation(x) for x in [*stopwords.words('english'), *nlp.Defaults.stop_words, *[str(x) for x in open(\"stop_words.txt\", \"r\").read().split(\" \")]]])]\n",
    "    # lemmatize the tokens \n",
    "    # lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                         Keywords  \\\n",
      "0    pay company resignation leave contract employment department labor employer resource human letter health resigned immediate clearance employee need coe file   \n",
      "1  people business job companies philippines outsourcing company salary good workers working minimum wage life employees jobs culture christmas process corporate   \n",
      "2        interview job offer company human resource salary applied position application hiring experience process companies time recruiter role passed asking red   \n",
      "3          boss team manager time supervisor hours tasks overtime management meeting coworkers company people person performance staff managers bad holiday angry   \n",
      "4                                          time job leave company office home working sick hours salary boss resign money team need experience long ill shift pay   \n",
      "\n",
      "   Topic ID  \n",
      "0         1  \n",
      "1         2  \n",
      "2         3  \n",
      "3         4  \n",
      "4         5  \n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer,\n",
    "                                min_df = 3, max_df=0.8, max_features=25000, \n",
    "                                use_idf=True, norm=None, token_pattern=None)\n",
    "tf_vectors = tf_vectorizer.fit_transform(df[\"Translated\"])  \n",
    "\n",
    "# Topic Modelling using LDA\n",
    "\n",
    "n_topics = 5\n",
    "lda = decomposition.LatentDirichletAllocation(n_components=n_topics, max_iter=35, \n",
    "                                              learning_method='online', learning_offset=55, n_jobs=1, random_state=420)\n",
    "W = lda.fit_transform(tf_vectors)\n",
    "H = lda.components_\n",
    "\n",
    "# Show top 15 relevant words for each topic\n",
    "\n",
    "num_words = 20\n",
    "vocab = np.array(tf_vectorizer.get_feature_names_out())\n",
    "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "topic_words = ([top_words(t) for t in H])\n",
    "topics = [' '.join(t) for t in topic_words]\n",
    "df_topics = pd.DataFrame(topics, columns=['Keywords'])\n",
    "df_topics['Topic ID'] = range(1, len(topics) + 1)\n",
    "print(df_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Submission 1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Topic 1: 0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic 3: 0.61\\nTopic 5: 0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Topic 5: 0.95\\nTopic 1: 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>Topic 4: 0.69\\nTopic 2: 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submission 5</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>Topic 5: 0.85\\nTopic 1: 0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic 1  Topic 2  Topic 3  Topic 4  Topic 5  dominant_topic  \\\n",
       "Submission 1     0.99      0.0     0.00     0.00     0.00               1   \n",
       "Submission 2     0.00      0.0     0.61     0.00     0.39               3   \n",
       "Submission 3     0.05      0.0     0.00     0.00     0.95               5   \n",
       "Submission 4     0.00      0.3     0.00     0.69     0.00               4   \n",
       "Submission 5     0.14      0.0     0.00     0.00     0.85               5   \n",
       "\n",
       "                                 breakdown  \n",
       "Submission 1                 Topic 1: 0.99  \n",
       "Submission 2  Topic 3: 0.61\\nTopic 5: 0.39  \n",
       "Submission 3  Topic 5: 0.95\\nTopic 1: 0.05  \n",
       "Submission 4   Topic 4: 0.69\\nTopic 2: 0.3  \n",
       "Submission 5  Topic 5: 0.85\\nTopic 1: 0.14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign topic to each submision\n",
    "topicid = [\"Topic \" + str(i+1) for i in range(lda.n_components)]\n",
    "postid = [\"Submission \" + str(i+1) for i in range(len(df[\"Translated\"]))]\n",
    "\n",
    "df_topics_lda = pd.DataFrame(np.round(W,2), columns=topicid, index=postid)\n",
    "significanttopic = np.argmax(df_topics_lda.values, axis=1)+1\n",
    "\n",
    "df_topics_lda['dominant_topic'] = significanttopic\n",
    "df_topics_lda['breakdown'] = df_topics_lda.apply(lambda row: '\\n'.join([f'{col}: {row[col]}' \n",
    "                                                        for col in sorted(df_topics_lda.columns, key=lambda x: row[x], reverse=True) \n",
    "                                                        if row[col] > 0 and col != 'dominant_topic']), axis=1)\n",
    "df_topics_lda.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE Clustering and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "# # Apply t-SNE for dimensionality reduction\n",
    "# tsne = TSNE(n_components=2, random_state=690)\n",
    "# tsne_result = tsne.fit_transform(df_topics_lda.iloc[:,:n_topics])\n",
    "\n",
    "# # Create a new dataframe with t-SNE coordinates and cluster labels\n",
    "# def split_text(text, max_length):\n",
    "#   lines = textwrap.wrap(text, width=max_length, break_long_words=False)\n",
    "#   return \"<br>\".join(lines)\n",
    "\n",
    "# df_topics_cluster = pd.DataFrame({'X': tsne_result[:, 0],\n",
    "#                                   'Y': tsne_result[:, 1],\n",
    "#                                   'Submission': df[\"Translated\"],\n",
    "#                                   'Engagement': df[\"Engagements\"],\n",
    "#                                   'Timestamp': df['Epoch'],\n",
    "#                                   'Cluster': df_topics_lda.reset_index()['dominant_topic'].astype(str), # topics via LDA\n",
    "#                                   'Breakdown': df_topics_lda.reset_index()['breakdown']})\n",
    "#                                   # 'Cluster': cluster_labels},                                         # clusters via K-means\n",
    "\n",
    "# df_topics_cluster['Submission'] = df_topics_cluster['Submission'].apply(lambda x: split_text(x, 40))\n",
    "# df_topics_cluster['Breakdown'] = df_topics_cluster['Breakdown'].str.replace('\\n','<br>')\n",
    "\n",
    "# df_top_10 = df_topics_cluster.sort_values('Engagement', ascending=False).groupby('Cluster').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutshell Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "# Apply t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2, random_state=120, perplexity=34, angle=0.8)\n",
    "tsne_result = tsne.fit_transform(df_topics_lda.iloc[:,:n_topics])\n",
    "\n",
    "# Create a new dataframe with t-SNE coordinates and cluster labels\n",
    "def split_text(text, max_length):\n",
    "  lines = textwrap.wrap(text, width=max_length, break_long_words=False)\n",
    "  return \"<br>\".join(lines)\n",
    "\n",
    "df_topics_cluster = pd.DataFrame({'X': tsne_result[:, 0],\n",
    "                                  'Y': tsne_result[:, 1],\n",
    "                                  'Submission': df[\"Translated\"],\n",
    "                                  'Engagement': df[\"Engagements\"],\n",
    "                                  'Timestamp': df['Epoch'],\n",
    "                                  'Cluster': df_topics_lda.reset_index()['dominant_topic'].astype(str), # topics via LDA\n",
    "                                  'Breakdown': df_topics_lda.reset_index()['breakdown']})\n",
    "                                  # 'Cluster': cluster_labels},                                         # clusters via K-means\n",
    "\n",
    "df_topics_cluster['Submission'] = df_topics_cluster['Submission'].apply(lambda x: split_text(x, 40))\n",
    "df_topics_cluster['Breakdown'] = df_topics_cluster['Breakdown'].str.replace('\\n','<br>')\n",
    "\n",
    "df_top_10 = df_topics_cluster.sort_values('Engagement', ascending=False).groupby('Cluster').head(10)\n",
    "\n",
    "# Plot submissions as colored points\n",
    "df_topics_cluster.sort_values('Cluster', key=lambda x: pd.to_numeric(x, errors='coerce'), inplace=True)\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#785ef0', '#dede00']\n",
    "\n",
    "Design_Book=[\n",
    "              '#ffb000', \n",
    "              '#785ef0', \n",
    "              '#dc267f', \n",
    "              '#fe6100', \n",
    "              '#57c4ff', \n",
    "              '#00cc96', \n",
    "              '#bcbd21', \n",
    "              '#a65628', \n",
    "              '#dede00',\n",
    "              '#984ea3',\n",
    "            ]\n",
    "\n",
    "fig = px.scatter(df_topics_cluster, x='X', y='Y', color='Cluster', \n",
    "                 title='Topic Clustering using LDA and t-SNE',\n",
    "                 hover_name='Submission',\n",
    "                 size='Engagement',\n",
    "                 color_discrete_sequence=Design_Book,\n",
    "                 hover_data={'X':False, 'Y':False, 'Cluster':False, 'Submission':False, 'Breakdown':True})\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=0,\n",
    "    y=-0.2*(1/10)-0.15,\n",
    "    text=\"Top 10 Most Frequent Keywords per Topic\",\n",
    "    showarrow=False,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    align='left',\n",
    "    font=dict(color='white', family='Arial', size=16, weight='normal')\n",
    "  )\n",
    "\n",
    "for i, keyword in enumerate(df_topics['Keywords']):\n",
    "  fig.add_annotation(\n",
    "    x=0,\n",
    "    y=-0.2*(i/5)-0.25,\n",
    "    text=\"Topic %d: %s\"%(i+1, keyword.replace(' ', ', ')),\n",
    "    showarrow=False,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    align='left',\n",
    "    font=dict(color=fig.data[i].marker['color'], family='Arial', size=16, weight='normal')\n",
    "  )\n",
    "\n",
    "SIZE_MULTIPLIER = 1\n",
    "\n",
    "fig.update_traces(mode='markers', \n",
    "                  opacity=1,\n",
    "                  marker=dict(\n",
    "                    sizemode='area',\n",
    "                    sizeref=2.*max(df['Engagements'])/((130*(SIZE_MULTIPLIER))**2), \n",
    "                    line_color='#1a181c',\n",
    "                    line_width=2),\n",
    "                  )\n",
    "\n",
    "fig.update_layout(height=1080*SIZE_MULTIPLIER,\n",
    "                  width=1480*SIZE_MULTIPLIER,\n",
    "                  xaxis=dict(\n",
    "                    gridwidth=2,\n",
    "                    title='',\n",
    "                    color='gray',\n",
    "                  ),\n",
    "                  yaxis=dict(\n",
    "                    gridwidth=2,\n",
    "                    title='',\n",
    "                    color='gray',\n",
    "                  ),\n",
    "                  margin=dict(b=360*SIZE_MULTIPLIER),\n",
    "                  title=dict(font=dict(color='white', family='Roboto', size=24, weight='bold')),\n",
    "                  showlegend=False, \n",
    "                  paper_bgcolor='#1a181c',\n",
    "                  plot_bgcolor='#1a181c',\n",
    "                )\n",
    "\n",
    "fig.update_xaxes(showline=True, \n",
    "                 linewidth=2, \n",
    "                 linecolor='#232024', \n",
    "                 gridcolor='#232024', \n",
    "                 zerolinecolor='#232024',\n",
    "                 title_font_color=\"white\")\n",
    "\n",
    "fig.update_yaxes(showline=True,\n",
    "                 linewidth=2, \n",
    "                 linecolor='#232024', \n",
    "                 gridcolor='#232024', \n",
    "                 zerolinecolor='#232024',\n",
    "                 title_font_color=\"#FFFFFF\")\n",
    "                \n",
    "\n",
    "# !pip install nbformat\n",
    "# restart kernel\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics_cluster['Date'] = pd.to_datetime(df_topics_cluster['Timestamp'], unit='s').dt.to_period('M')\n",
    "# df_topics_cluster = df_topics_cluster.sort_values(by='Timestamp')\n",
    "\n",
    "# total_count = df_topics_cluster.groupby('Date').nunique()\n",
    "# total_count = total_count['Submission'].cumsum()\n",
    "# cumulative_count = df_topics_cluster.groupby(['Date','Cluster']).nunique()\n",
    "# cumulative_count = cumulative_count.pivot_table('Submission', 'Date', 'Cluster').fillna(0).cumsum()\n",
    "\n",
    "# rel_freq = cumulative_count.div(total_count, axis=0)\n",
    "# rel_freq = rel_freq.stack(0).reset_index()\n",
    "# rel_freq.columns = ['Date', 'Cluster', 'Relative Frequency']\n",
    "# rel_freq['Date'] = [x.strftime('%b %Y') for x in rel_freq['Date']]\n",
    "\n",
    "# monthly_count = df_topics_cluster.groupby(['Date','Cluster']).size()\n",
    "# monthly_count = monthly_count.reset_index()\n",
    "# monthly_count.columns = ['Date', 'Cluster', 'Frequency']\n",
    "# monthly_count['Date'] = [x.strftime('%b %Y') for x in monthly_count['Date']]\n",
    "\n",
    "# cumulative_count = cumulative_count.stack(0).reset_index()\n",
    "# cumulative_count.columns = ['Date', 'Cluster', 'Frequency']\n",
    "# cumulative_count['Date'] = [x.strftime('%b %Y') for x in cumulative_count['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.area(monthly_count, x='Date', y='Frequency', color='Cluster',\n",
    "#               title='Relative Frequency vs Time',\n",
    "#               color_discrete_sequence=Design_Book,\n",
    "#               labels={'Relative_Frequency': 'Relative Frequency', 'Date': 'Date'}\n",
    "#             )\n",
    "\n",
    "# fig.update_xaxes(nticks=7)\n",
    "\n",
    "# fig.update_layout(height=1080,\n",
    "#                   width=2160,\n",
    "#                   xaxis=dict(\n",
    "#                     gridwidth=2,\n",
    "#                     title='',\n",
    "#                     color='gray',\n",
    "#                   ),\n",
    "#                   yaxis=dict(\n",
    "#                     gridwidth=2,\n",
    "#                     title='',\n",
    "#                     color='gray',\n",
    "#                   ),\n",
    "#                   title=dict(font=dict(color='white', family='Roboto', size=24, weight='bold')),\n",
    "#                   legend=dict(title=\"Topic\", font=dict(color='white', family='Roboto', size=16, weight='normal')),\n",
    "#                   paper_bgcolor='#1a181c',\n",
    "#                   plot_bgcolor='#1a181c',\n",
    "#                 )\n",
    "\n",
    "# fig.update_xaxes(showline=True, \n",
    "#                  linewidth=2, \n",
    "#                  linecolor='#232024', \n",
    "#                  gridcolor='#232024', \n",
    "#                  zerolinecolor='#232024',\n",
    "#                  title_font_color=\"white\")\n",
    "\n",
    "# fig.update_yaxes(showline=True,\n",
    "#                  linewidth=2, \n",
    "#                  linecolor='#232024', \n",
    "#                  gridcolor='#232024', \n",
    "#                  zerolinecolor='#232024',\n",
    "#                  title_font_color=\"#FFFFFF\")\n",
    "\n",
    "# # Show the plot\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
