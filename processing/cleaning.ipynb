{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import string \n",
    "import markdown \n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "import csv\n",
    "import emoji\n",
    "import nltk\n",
    "import numpy as np\n",
    "import spacy    \n",
    "import spacy_transformers\n",
    "import unicodedata\n",
    "import sys\n",
    "from deep_translator import GoogleTranslator\n",
    "import math\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "hot = pd.read_csv(\"../dataset/raw/hot.csv\")\n",
    "top = pd.read_csv(\"../dataset/raw/top.csv\")\n",
    "controversial = pd.read_csv(\"../dataset/raw/controversial.csv\")\n",
    "new = pd.read_csv(\"../dataset/raw/new.csv\")\n",
    "\n",
    "df = pd.concat([hot, top, controversial, new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1978, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing empty string and zero-length spaces\n",
    "\n",
    "df['Content'] = df['Content'].replace('', np.nan)\n",
    "df['Content'] = df['Content'].replace('\\u200b', np.nan)\n",
    "\n",
    "df['Title'] = df['Title'].replace('', np.nan)\n",
    "df['Title'] = df['Title'].replace('\\u200b', np.nan)\n",
    "\n",
    "df.dropna(subset=['Content'], inplace=True, ignore_index=True)\n",
    "df.dropna(subset=['Title'], inplace=True, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_REGEX = r\".*(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*).*\"\n",
    "punctuation = \"\".join((chr(i) for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P')))\n",
    "\n",
    "# Remove URLs\n",
    "def remove_url(cell):\n",
    "    return re.sub(URL_REGEX, \"\", str(cell))\n",
    "\n",
    "# Convert markdown to plaintext \n",
    "def md_to_text(cell):\n",
    "    html = markdown.markdown(cell)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Replace NaN and \\n \n",
    "def remove_NaN_newline(cell):\n",
    "    return re.sub(r\"(\\n|NaN|nan)\", \" \", str(cell))\n",
    "\n",
    "def remove_punctuation(cell):\n",
    "    return cell.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "# Convert abbreviations and slangs\n",
    "def replace_abbrv(cell):\n",
    "    user_string = str(cell)\n",
    "    user_string = user_string.split(\" \")\n",
    "    j = 0\n",
    "    for _str in user_string:\n",
    "        fileName = \"slang.txt\"\n",
    "        accessMode = \"r\"\n",
    "        with open(fileName, accessMode) as myCSVfile:\n",
    "            dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in dataFromFile:\n",
    "                # if re.findall(fr\"{_str}\", row[0], flags=re.IGNORECASE):\n",
    "                if _str.lower() == row[0].lower():\n",
    "                    user_string[j] = row[1]\n",
    "            myCSVfile.close()\n",
    "        j = j + 1\n",
    "    return ' '.join(user_string)\n",
    "\n",
    "# Remove emoji\n",
    "def remove_emoji(text):\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(cell):\n",
    "    return re.sub(r\"\\d+\", \" \", str(cell))\n",
    "\n",
    "# Convert to lowercase\n",
    "def lowercase(cell):\n",
    "    return str(cell).lower()\n",
    "\n",
    "# Convert time to Unix timestamp\n",
    "def convert_utc(cell):\n",
    "    date = [int(x) for x in cell.split(\" \")[0].split(\"-\")] \n",
    "    return datetime(date[0],date[1],date[2]).strftime('%s')\n",
    "\n",
    "# Remove names using spacy's named entity recognition \n",
    "def remove_names(text):\n",
    "    doc = nlp(str(text))\n",
    "    newString = str(text)\n",
    "    for e in reversed(doc.ents):\n",
    "        if e.label_ == \"PERSON\": # Only if the entity is a PERSON\n",
    "            newString = newString[:e.start_char] + newString[e.start_char + len(e.text):]\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].apply(replace_abbrv)\n",
    "df['Content'] = df['Content'].apply(remove_url)\n",
    "df['Content'] = df['Content'].apply(md_to_text)\n",
    "df['Content'] = df['Content'].apply(remove_NaN_newline)\n",
    "df['Content'] = df['Content'].apply(remove_emoji)\n",
    "df['Content'] = df['Content'].apply(remove_numbers)\n",
    "df['Content'] = df['Content'].apply(lowercase)\n",
    "df['Content'] = df['Content'].apply(remove_punctuation)\n",
    "df['Content'] = df['Content'].apply(remove_names)\n",
    "\n",
    "df['Title'] = df['Title'].apply(replace_abbrv)\n",
    "df['Title'] = df['Title'].apply(remove_url)\n",
    "df['Title'] = df['Title'].apply(md_to_text)\n",
    "df['Title'] = df['Title'].apply(remove_NaN_newline)\n",
    "df['Title'] = df['Title'].apply(remove_emoji)\n",
    "df['Title'] = df['Title'].apply(remove_numbers)\n",
    "df['Title'] = df['Title'].apply(lowercase)\n",
    "df['Title'] = df['Title'].apply(remove_punctuation)\n",
    "df['Title'] = df['Title'].apply(remove_names)\n",
    "\n",
    "df['Epoch'] = df['Timestamp'].apply(convert_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new column Title+Content\n",
    "df.insert(4, \"Title+Content\", df[\"Title\"] + \" \" + df[\"Content\"]) \n",
    "df['Title+Content'] = df['Title+Content'].replace('', np.nan)\n",
    "df['Title+Content'] = df['Title+Content'].replace('\\u200b', np.nan)\n",
    "df.dropna(subset=['Title+Content'], inplace=True, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(text):\n",
    "    if len(text) > 5000:\n",
    "        text_1 = GoogleTranslator(source='tl', target='en').translate(text[:math.floor(len(text)/2)]) \n",
    "        text_2 = GoogleTranslator(source='tl', target='en').translate(text[math.floor(len(text)/2):]) \n",
    "        return text_1 + \" \" + text_2\n",
    "    else:   \n",
    "        return GoogleTranslator(source='tl', target='en').translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_1 = df['Title+Content'][:500].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2 = df['Title+Content'][500:1000].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_3 = df['Title+Content'][1000:1500].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_4 = df['Title+Content'][1500:2000].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_5 = df['Title+Content'][2000:].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([trans_1, trans_2, trans_3, trans_4, trans_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.to_frame().rename(columns={\"Title+Content\":\"Translated\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the translated string\n",
    "\n",
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(remove_names)\n",
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(remove_punctuation)\n",
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(lowercase)\n",
    "df.dropna(subset=['Translated'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new column Engagements with the formula (upvotes count + comment count) * upvote ratio\n",
    "\n",
    "df_test[\"Engagements\"] = (df[\"Upvotes Count\"] + df[\"Comments Count\"]) * df[\"Upvote Ratio\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert to the main DataFrame\n",
    "\n",
    "df.insert(5, \"Translated\", df_test[\"Translated\"])\n",
    "df.insert(8, \"Engagements\", df_test[\"Engagements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to CSV\n",
    "\n",
    "df.to_csv(f\"../dataset/_compiled/Compiled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1977, 14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
