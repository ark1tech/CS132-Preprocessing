{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/ray/Documents/Obsidian/Arki's Vault/2_CS 132/_Code/scraper/.scrape/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # pip install pandas\n",
    "import re # pip install re\n",
    "import string \n",
    "import markdown # pip install markdown\n",
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import emoji\n",
    "import nltk\n",
    "import numpy as np\n",
    "import spacy    \n",
    "import spacy_transformers\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "hot = pd.read_csv(\"../dataset/raw/hot.csv\")\n",
    "top = pd.read_csv(\"../dataset/raw/top.csv\")\n",
    "controversial = pd.read_csv(\"../dataset/raw/controversial.csv\")\n",
    "new = pd.read_csv(\"../dataset/raw/new.csv\")\n",
    "\n",
    "df = pd.concat([hot, top, controversial, new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1978, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'] = df['Content'].replace('', np.nan)\n",
    "df['Content'] = df['Content'].replace('\\u200b', np.nan)\n",
    "\n",
    "df['Title'] = df['Title'].replace('', np.nan)\n",
    "df['Title'] = df['Title'].replace('\\u200b', np.nan)\n",
    "\n",
    "df.dropna(subset=['Content'], inplace=True, ignore_index=True)\n",
    "df.dropna(subset=['Title'], inplace=True, ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "URL_REGEX = r\".*(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*).*\"\n",
    "punctuation = \"\".join((chr(i) for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P')))\n",
    "\n",
    "# Remove URLs\n",
    "def remove_url(cell):\n",
    "    return re.sub(URL_REGEX, \"\", str(cell))\n",
    "\n",
    "# Convert markdown to plaintext \n",
    "def md_to_text(cell):\n",
    "    html = markdown.markdown(cell)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Replace NaN and \\n \n",
    "def remove_NaN_newline(cell):\n",
    "    return re.sub(r\"(\\n|NaN|nan)\", \" \", str(cell))\n",
    "\n",
    "def remove_punctuation(cell):\n",
    "    return cell.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "# Convert slangs\n",
    "def replace_abbrv(cell):\n",
    "    user_string = str(cell)\n",
    "    user_string = user_string.split(\" \")\n",
    "    j = 0\n",
    "    for _str in user_string:\n",
    "        fileName = \"slang.txt\"\n",
    "        accessMode = \"r\"\n",
    "        with open(fileName, accessMode) as myCSVfile:\n",
    "            dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in dataFromFile:\n",
    "                # if re.findall(fr\"{_str}\", row[0], flags=re.IGNORECASE):\n",
    "                if _str.lower() == row[0].lower():\n",
    "                    user_string[j] = row[1]\n",
    "            myCSVfile.close()\n",
    "        j = j + 1\n",
    "    return ' '.join(user_string)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def remove_numbers(cell):\n",
    "    return re.sub(r\"\\d+\", \" \", str(cell))\n",
    "\n",
    "def lowercase(cell):\n",
    "    return str(cell).lower()\n",
    "\n",
    "def convert_utc(cell):\n",
    "    date = [int(x) for x in cell.split(\" \")[0].split(\"-\")] \n",
    "    return datetime(date[0],date[1],date[2]).strftime('%s')\n",
    "\n",
    "def remove_names(text):\n",
    "    doc = nlp(str(text))\n",
    "    newString = str(text)\n",
    "    for e in reversed(doc.ents):\n",
    "        if e.label_ == \"PERSON\": # Only if the entity is a PERSON\n",
    "            newString = newString[:e.start_char] + newString[e.start_char + len(e.text):]\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].apply(replace_abbrv)\n",
    "df['Content'] = df['Content'].apply(remove_url)\n",
    "df['Content'] = df['Content'].apply(md_to_text)\n",
    "df['Content'] = df['Content'].apply(remove_NaN_newline)\n",
    "df['Content'] = df['Content'].apply(remove_emoji)\n",
    "df['Content'] = df['Content'].apply(remove_numbers)\n",
    "df['Content'] = df['Content'].apply(lowercase)\n",
    "df['Content'] = df['Content'].apply(remove_punctuation)\n",
    "df['Content'] = df['Content'].apply(remove_names)\n",
    "\n",
    "df['Title'] = df['Title'].apply(replace_abbrv)\n",
    "df['Title'] = df['Title'].apply(remove_url)\n",
    "df['Title'] = df['Title'].apply(md_to_text)\n",
    "df['Title'] = df['Title'].apply(remove_NaN_newline)\n",
    "df['Title'] = df['Title'].apply(remove_emoji)\n",
    "df['Title'] = df['Title'].apply(remove_numbers)\n",
    "df['Title'] = df['Title'].apply(lowercase)\n",
    "df['Title'] = df['Title'].apply(remove_punctuation)\n",
    "df['Title'] = df['Title'].apply(remove_names)\n",
    "\n",
    "df['Epoch'] = df['Timestamp'].apply(convert_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(4, \"Title+Content\", df[\"Title\"] + \" \" + df[\"Content\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title+Content'] = df['Title+Content'].replace('', np.nan)\n",
    "df['Title+Content'] = df['Title+Content'].replace('\\u200b', np.nan)\n",
    "df.dropna(subset=['Title+Content'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1978, 12)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(text):\n",
    "    if len(text) > 5000:\n",
    "        text_1 = GoogleTranslator(source='tl', target='en').translate(text[:math.floor(len(text)/2)]) \n",
    "        text_2 = GoogleTranslator(source='tl', target='en').translate(text[math.floor(len(text)/2):]) \n",
    "        return text_1 + \" \" + text_2\n",
    "    else:   \n",
    "        return GoogleTranslator(source='tl', target='en').translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_1 = df['Title+Content'][:500].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2 = df['Title+Content'][500:1000].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_3 = df['Title+Content'][1000:1500].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_4 = df['Title+Content'][1500:2000].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_5 = df['Title+Content'][2000:].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([trans_1, trans_2, trans_3, trans_4, trans_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.to_frame().rename(columns={\"Title+Content\":\"Translated\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(remove_names)\n",
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(remove_punctuation)\n",
    "df_test[\"Translated\"] = df_test[\"Translated\"].apply(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Translated'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Engagements\"] = (df[\"Upvotes Count\"] + df[\"Comments Count\"]) / df[\"Upvote Ratio\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(5, \"Translated\", df_test[\"Translated\"])\n",
    "df.insert(8, \"Engagements\", df_test[\"Engagements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../dataset/_compiled/Compiled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
